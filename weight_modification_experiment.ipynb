{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Copyright 2025 Bytedance Ltd. and/or its affiliates.\n",
    "# SPDX-License-Identifier: Apache-2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from copy import deepcopy\n",
    "from typing import (\n",
    "    Any,\n",
    "    AsyncIterable,\n",
    "    Callable,\n",
    "    Dict,\n",
    "    Generator,\n",
    "    List,\n",
    "    NamedTuple,\n",
    "    Optional,\n",
    "    Tuple,\n",
    "    Union,\n",
    ")\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "from PIL import Image\n",
    "import torch\n",
    "from accelerate import infer_auto_device_map, load_checkpoint_and_dispatch, init_empty_weights\n",
    "\n",
    "from data.transforms import ImageTransform\n",
    "from data.data_utils import pil_img2rgb, add_special_tokens\n",
    "from modeling.bagel import (\n",
    "    BagelConfig, Bagel, Qwen2Config, Qwen2ForCausalLM, SiglipVisionConfig, SiglipVisionModel\n",
    ")\n",
    "from modeling.qwen2 import Qwen2Tokenizer\n",
    "from modeling.bagel.qwen2_navit import NaiveCache\n",
    "from modeling.autoencoder import load_ae\n",
    "from safetensors.torch import load_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load qwen2.5\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "qwen_path = \"/home/jake0360/BAGEL/Qwen2.5-7B-Instruct\"\n",
    "qwen = AutoModelForCausalLM.from_pretrained(\n",
    "    qwen_path,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\"\n",
    ").to(\"cuda\").eval()\n",
    "\n",
    "print(\"Loaded qwen2.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_path = \"/home/jake0360/projects/def-sreddy/checkpoints/BAGEL-7B-MoT\"  # Download from https://huggingface.co/ByteDance-Seed/BAGEL-7B-MoT\n",
    "\n",
    "# LLM config preparing\n",
    "llm_config = Qwen2Config.from_json_file(os.path.join(model_path, \"llm_config.json\"))\n",
    "llm_config.qk_norm = True\n",
    "llm_config.tie_word_embeddings = False\n",
    "llm_config.layer_module = \"Qwen2MoTDecoderLayer\"\n",
    "\n",
    "# ViT config preparing\n",
    "vit_config = SiglipVisionConfig.from_json_file(os.path.join(model_path, \"vit_config.json\"))\n",
    "vit_config.rope = False\n",
    "vit_config.num_hidden_layers = vit_config.num_hidden_layers - 1\n",
    "\n",
    "# VAE loading\n",
    "vae_model, vae_config = load_ae(local_path=os.path.join(model_path, \"ae.safetensors\"))\n",
    "\n",
    "# Bagel config preparing\n",
    "config = BagelConfig(\n",
    "    visual_gen=True,\n",
    "    visual_und=True,\n",
    "    llm_config=llm_config, \n",
    "    vit_config=vit_config,\n",
    "    vae_config=vae_config,\n",
    "    vit_max_num_patch_per_side=70,\n",
    "    connector_act='gelu_pytorch_tanh',\n",
    "    latent_patch_size=2,\n",
    "    max_latent_size=64,\n",
    ")\n",
    "\n",
    "with init_empty_weights():\n",
    "    language_model = Qwen2ForCausalLM(llm_config)\n",
    "    vit_model      = SiglipVisionModel(vit_config)\n",
    "    model          = Bagel(language_model, vit_model, config)\n",
    "    model.vit_model.vision_model.embeddings.convert_conv2d_to_linear(vit_config, meta=True)\n",
    "\n",
    "# Tokenizer Preparing\n",
    "tokenizer = Qwen2Tokenizer.from_pretrained(model_path)\n",
    "tokenizer, new_token_ids, _ = add_special_tokens(tokenizer)\n",
    "\n",
    "# Image Transform Preparing\n",
    "vae_transform = ImageTransform(1024, 512, 16)\n",
    "vit_transform = ImageTransform(980, 224, 14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import json, os\n",
    "from safetensors import safe_open\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import io\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "import contextlib, sys\n",
    "\n",
    "bagel_path = \"/home/jake0360/projects/def-sreddy/checkpoints/BAGEL-7B-MoT/ema.safetensors\"\n",
    "qwen_dir   = \"/home/jake0360/BAGEL/Qwen2.5-7B-Instruct\"\n",
    "index_file = os.path.join(qwen_dir, \"model.safetensors.index.json\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# load weights\n",
    "with open(index_file, \"r\") as f:\n",
    "    index = json.load(f)[\"weight_map\"]\n",
    "\n",
    "qwen_shards = {k: os.path.join(qwen_dir, v) for k, v in index.items()}\n",
    "print(f\"Indexed {len(qwen_shards)} Qwen2.5 tensors across {len(set(qwen_shards.values()))} shards.\")\n",
    "\n",
    "# compare weights\n",
    "def compare_tensors(t1, t2):\n",
    "    t1 = t1.to(device, dtype=torch.float32)\n",
    "    t2 = t2.to(device, dtype=torch.float32)\n",
    "    # delta mean\n",
    "    mean_diff = (t1 - t2).abs().mean().item()\n",
    "    # cos similarity\n",
    "    cosine = F.cosine_similarity(t1.flatten(), t2.flatten(), dim=0).item()\n",
    "    del t1, t2\n",
    "    torch.cuda.empty_cache()\n",
    "    return mean_diff, cosine\n",
    "\n",
    "layer_diffs = {}\n",
    "\n",
    "with safe_open(bagel_path, framework=\"pt\") as f_bagel:\n",
    "    bagel_keys = [k for k in f_bagel.keys() if k.startswith(\"language_model.\")]\n",
    "    for k in tqdm(bagel_keys, desc=\"Comparing BAGEL vs Qwen2.5\"):\n",
    "        layer_name = k.replace(\"language_model.\", \"\")\n",
    "        if layer_name not in qwen_shards:\n",
    "            continue\n",
    "        qwen_file = qwen_shards[layer_name]\n",
    "        try:\n",
    "            bagel_w = f_bagel.get_tensor(k)\n",
    "            with safe_open(qwen_file, framework=\"pt\") as f_q:\n",
    "                ref_w = f_q.get_tensor(layer_name)\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "        if bagel_w.shape != ref_w.shape:\n",
    "            continue\n",
    "\n",
    "        md, cs = compare_tensors(bagel_w, ref_w)\n",
    "        group = \".\".join(layer_name.split(\".\")[:3])\n",
    "        layer_diffs.setdefault(group, []).append((md, cs))\n",
    "\n",
    "\n",
    "output_path = \"layer_diff_summary.txt\"\n",
    "\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"=== Layer Δ Summary ===\\n\")\n",
    "\n",
    "    for mod, vals in sorted(layer_diffs.items(), key=lambda x: layer_sort_key(x[0])):\n",
    "        md = sum(v[0] for v in vals) / len(vals)\n",
    "        cs = sum(v[1] for v in vals) / len(vals)\n",
    "        bar = \"█\" * int((1 - cs) * 40) + \"░\" * int(cs * 40)\n",
    "        f.write(f\"{mod:25s} | Δmean={md:.3e} | cos={cs:.4f} | {bar}\\n\")\n",
    "\n",
    "    f.write(\"\\nDone — compared BAGEL vs Qwen2.5-7B-Instruct.\\n\")\n",
    "\n",
    "print(f\"Output: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from safetensors import safe_open\n",
    "\n",
    "bagel_path = \"/home/jake0360/projects/def-sreddy/checkpoints/BAGEL-7B-MoT/ema.safetensors\"\n",
    "\n",
    "with safe_open(bagel_path, framework=\"pt\") as f:\n",
    "    all_keys = list(f.keys())\n",
    "\n",
    "for k in all_keys:\n",
    "    if \"moe\" not in k.lower():\n",
    "        print(k)"
   ]
  }
 ],
 "metadata": {
  "fileId": "1bfaa82d-51b0-4c13-9e4c-295ba28bcd8a",
  "filePath": "/mnt/bn/seed-aws-va/chaorui/code/cdt-hf/notebooks/chat.ipynb",
  "kernelspec": {
   "display_name": "BAGEL (ComputeCanada)",
   "language": "python",
   "name": "bagel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
